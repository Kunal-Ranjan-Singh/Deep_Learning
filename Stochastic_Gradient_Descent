import numpy as np
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Load and preprocess the data
data = load_diabetes()
X, y = data.data, data.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

y_mean = y_train.mean()
y_std = y_train.std()
y_train = (y_train - y_mean) / y_std
y_test = (y_test - y_mean) / y_std

# Define the stochastic gradient descent function
def stochastic_gradient_descent(X, y, learning_rate=0.001, num_epochs=100, batch_size=1):
    num_samples, num_features = X.shape
    weights = np.zeros(num_features)
    bias = 0

    for epoch in range(num_epochs):
        # Shuffle the data
        indices = np.arange(num_samples)
        np.random.shuffle(indices)
        X_shuffled = X[indices]
        y_shuffled = y[indices]

        for i in range(0, num_samples, batch_size):
            X_batch = X_shuffled[i:i+batch_size]
            y_batch = y_shuffled[i:i+batch_size]

            # Predictions and errors
            predictions = np.dot(X_batch, weights) + bias
            errors = predictions - y_batch

            # Calculate gradients
            gradient_weights = np.dot(X_batch.T, errors) / batch_size
            gradient_bias = np.sum(errors) / batch_size

            # Update weights and bias
            weights -= learning_rate * gradient_weights
            bias -= learning_rate * gradient_bias

        # Print loss every 10 epochs
        if epoch % 10 == 0:
            loss = np.mean((np.dot(X, weights) + bias - y) ** 2)
            print(f"Epoch {epoch}, Loss: {loss:.4f}")

    return weights, bias

# Train the model
weights, bias = stochastic_gradient_descent(X_train_scaled, y_train)

# Evaluate the model on the test set
predictions = np.dot(X_test_scaled, weights) + bias
mse = np.mean((predictions - y_test) ** 2)
print("Mean Squared Error on Test Set (normalized):", mse)

# Denormalize predictions and y_test for MSE in the original scale
predictions_original = predictions * y_std + y_mean
y_test_original = y_test * y_std + y_mean
mse_original = np.mean((predictions_original - y_test_original) ** 2)
print("Mean Squared Error on Test Set (original scale):", mse_original)
